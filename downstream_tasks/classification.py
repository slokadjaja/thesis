"""Compare performance of TS classification using SAX and VAE encodings"""
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, recall_score, precision_score
from sklearn.preprocessing import StandardScaler
from utils import get_or_create_experiment, get_dataset, get_sax_encoding, get_vae_encoding, get_vqshape_encoding
from tqdm import tqdm
from typing import Callable
import pandas as pd
import numpy as np
from dotenv import load_dotenv
from azure.identity import ClientSecretCredential
import os
import mlflow


def decision_tree_classifier(X_train, y_train, X_test, y_test):
    # Fit decision tree classifier
    clf = DecisionTreeClassifier().fit(X_train, y_train)

    # Calculate F1 and accuracy score
    y_pred = clf.predict(X_test)
    f1 = f1_score(y_test, y_pred, average='macro')
    acc = accuracy_score(y_test, y_pred)
    # cm = confusion_matrix(y_test, y_pred)
    p = precision_score(y_test, y_pred, average='macro', zero_division=0)
    r = recall_score(y_test, y_pred, average='macro', zero_division=0)

    y_pred_train = clf.predict(X_train)
    train_acc = accuracy_score(y_train, y_pred_train)

    # print(f"Confusion matrix:\n{cm}")
    # print(f"F1 score: {f1:.2f}")
    # print(f"Accuracy: {acc:.2f}")

    return {"train_accuracy": train_acc, "accuracy": acc, "f1": f1, "precision": p, "recall": r}


def run_experiment(dataset: str, iters_per_setting: int, enc_function: Callable, model_name: str, params):
    X_train, y_train, X_test, y_test = get_dataset(dataset)

    # todo adjust to models
    scaler = StandardScaler()
    X_train = np.expand_dims(scaler.fit_transform(X_train), axis=1)
    X_test = np.expand_dims(scaler.transform(X_test), axis=1)

    # Get encodings
    X_train_emb = enc_function(X_train, params)
    X_test_emb = enc_function(X_test, params)

    # Train decision tree classifier using encodings
    results = []
    for i in range(iters_per_setting):
        results.append(decision_tree_classifier(X_train_emb, y_train, X_test_emb, y_test))

    results = [d | {"dataset": dataset, "model": model_name} for d in results]
    return results


def classification(datasets: list[str], vae_models: list[str], sax_params: list[dict[str, int]],
                   iters_per_setting: int, azure=True) -> None:
    """
    Perform time series classification using SAX and VAE-based encodings.

    This method evaluates the performance of time series classification using symbolic representations
    generated by SAX and VAEs. It trains  a Decision Tree classifier on these representations and computes metrics such
    as accuracy, F1-score, precision, and recall for each dataset and encoding method.

    Args:
        datasets: List of datasets to classify.
        vae_models: List of trained VAE model names to use for encoding.
        sax_params: List of dictionaries containing SAX parameters (n_segments and alphabet_size)
        iters_per_setting: Number of iterations to repeat the experiment for each dataset and encoding method.
        azure: Whether to use Azure ML for storing results. Defaults to True.
    """

    # Collect results across experiments
    all_results = []

    total_iters = len(datasets) * (len(vae_models) + len(sax_params) + 1)
    with tqdm(total=total_iters) as pbar:
        for dataset in datasets:
            # VQShape experiment
            vqshape_result = run_experiment(dataset, iters_per_setting, get_vqshape_encoding, "vqshape", None)
            all_results = all_results + vqshape_result
            pbar.update(1)

            # SAX experiments
            for idx, sax_param in enumerate(sax_params):
                sax_results = run_experiment(dataset, iters_per_setting, get_sax_encoding, f"sax_{idx}",
                                             params=sax_param)
                all_results = all_results + sax_results
                pbar.update(1)

            # VAE experiments
            for vae_model in vae_models:
                vae_results = run_experiment(dataset, iters_per_setting, get_vae_encoding, vae_model,
                                             params=vae_model)
                all_results = all_results + vae_results
                pbar.update(1)

    all_results = pd.DataFrame.from_records(all_results)
    all_results.to_csv("classification_results.csv")

    summary_df = pd.DataFrame()
    for metric in ["train_accuracy", "accuracy", "f1", "precision", "recall"]:
        res = all_results.groupby(["dataset", "model"], as_index=False)[metric].mean()
        if summary_df.empty:
            summary_df = res
        else:
            summary_df = summary_df.merge(res, on=["dataset", "model"], how="outer")

    print(summary_df)
    summary_df.to_csv(f"classification_results_summary.csv")

    if azure:
        load_dotenv()
        credential = ClientSecretCredential(os.environ["AZURE_TENANT_ID"], os.environ["AZURE_CLIENT_ID"],
                                            os.environ["AZURE_CLIENT_SECRET"])
        mlflow.set_tracking_uri(os.environ["TRACKING_URI"])

        experiment_id = get_or_create_experiment("classification")
        mlflow.set_experiment(experiment_id=experiment_id)

        with mlflow.start_run(experiment_id=experiment_id, run_name="classification"):
            mlflow.log_artifact("classification_results.csv")
            mlflow.log_artifact("classification_results_summary.csv")


if __name__ == "__main__":
    # Define experiment parameters
    cls_datasets = ["Wine", "Rock", "Plane", "ArrowHead", "p2s", "FordA", "FordB"]
    vae_list = ["ArrowHead_p16_a32", "Wine_p16_a32", "p2s_p128_a32"]
    sax_params = [{"n_segments": 16, "alphabet_size": 32}, {"n_segments": 16, "alphabet_size": 48}]
    n_iters = 10

    classification(cls_datasets, vae_list, sax_params, n_iters, azure=False)
